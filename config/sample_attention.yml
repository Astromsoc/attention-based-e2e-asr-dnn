# filepaths
# ------------------------------------------------
TRN_FOLDER: data/train-clean-100
DEV_FOLDER: data/dev-clean
TST_FOLDER: data/test-clean
EXP_FOLDER: experiments

# training
# ------------------------------------------------
seed: 11785
epochs: 100
batch_size: 96
num_workers: 15
accu_grad: 1
grad_norm: 5.0
eval_ld_interval: 1
init_force: false
tf_rate: 1.0
max_savings: 3
use_specaug: false

# wandb
# ------------------------------------------------
wandb:
  use: true
  configs:
    project: 
    reinit: true
    entity: 
    
# finetuning
# ------------------------------------------------
finetune:
  use: false
  checkpoint: 


# configurations to train the model
# ------------------------------------------------
model:
  tag: base-LAS
  configs:
    listener_configs:
      input_dim: 15
      uniform_hid_dim: 512
      lstm_layers: 1
      plstm_layers: 3
      bidirectional: true
      init_dropout: 0.3
      mid_dropout: 0.3
      final_dropout: 0.3
    speller_configs:
      # encoder + attention
      att_proj_dim: 256
      att_heads: 1
      att_dropout: 0.0
      # decoder embeddings
      dec_emb_dim: 512
      dec_emb_dropout: 0.0
      # decoder lstm cells
      dec_lstm_hid_dim: 512
      dec_lstm_out_dim: 256
      dec_lstm_dropout: 0.0
      # trivials
      CHR_MAX_STEPS: 600
      USE_GREEDY: true

# optimizer
optimizer:
  name: adamw
  configs:
    lr: 0.001
    weight_decay: 5.0e-6
    amsgrad: true

# scalar
scaler:
  use: true

# batch scheduler
batch_scheduler:
  use: false
  configs:
    warmup_epochs: 0.5

# epoch scheduler
epoch_scheduler:
  use: false

# tf rate scheduler
tf_rate_scheduler:
  use: false
  configs:
    factor: 0.05
    interval: 5

# dropout scheduler
dropout_scheduler:
  use: false
  configs:
    0: 1
    30: 2
    60: 1.5
    80: 0.8
    95: 0.8
    105: 1.25

# criterion: fixed to CrossEntropyLoss(reduction='none')